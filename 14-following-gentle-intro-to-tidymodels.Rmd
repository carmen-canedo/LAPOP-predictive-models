---
title: "13 - Following Gentle Intro to Tidymodels"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# Notes from Gentle Intro to Tidymodels

These notes are for personal reference only, the content comes from Gentle Intro to Tidymodels by Edgar Ruiz. The article can be found [here](https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/).

Tidymodels is a group of packages that doesn't implement the statistical models themselves, but simplifies data pre-processing and results validation.

# Four tidymodels packages sampled by modeling step:

## Pre-Process
* `rsample` - different types of re-samples
* `recipes` - transformations for model data pre-processing

## Train
* `parsnip` - a common interface for model creation

## Validate
* `yardstick` - measure model performance

# Iris Example
Loading in `tidymodels` also loads in `dplyr` and `ggplot` along with other packages from `tidyverse`, so in this case `tidymodels` is the only package we need to load.

```{r, message=FALSE}
library(tidymodels)
```

## Pre-Process
Pre-processing is where you would clean the data to prepare it for modeling. Most transformations can be completed with `tidyverse`.

## Data Sampling
`initial_split()` creates two datasets:
1. Training set
  - 3/4 of data held here
2: Testing set
  - 1/4 of data used for testing
This then creates an `rplit` object.

```{r}
iris_split <- initial_split(iris, prop = 0.6) 
#prop argument changes the proportion of data in each set
iris_split #Results: row count for training/testing/total
```

`training()` and `testing()` access observations from their respective datasets.

```{r}
#Viewing data from training set
iris_split %>% 
  training() %>% 
  glimpse()
```

## Pre-process interface
`recipes` package provides a data pre-processing interface.

* `recipe()` - starts a new set of transformations to be applied. Main argument is the model's formula. (Similar to `ggplot()`)
* `prep()` - executes the transformations on top of the data that is supplied (the training data, most typically)

*Each data transformation is a step* and functions correspond to specific steps.

* `step_corr()` - removes variables that have large absolute correlations with other variables
* `step_center()` - normalizes numeric data to have a mean of zero
* `step_scale()` - normalizes numeric data to have an SD of 1

These can be used in conjunction with `all_outcomes()` and `all_predictors()` to group variables.

```{r}
iris_recipe <- training(iris_split) %>% 
  recipe(Species ~.) %>% 
  step_corr(all_predictors()) %>% 
  step_center(all_predictors(), -all_outcomes()) %>% 
  step_scale(all_predictors(), -all_outcomes()) %>% 
  prep()

#Calling object prints out details about the recipe
iris_recipe
```

## Execute the pre-processing
To apply the same transformations on the testing data, we use `bake()`.

```{r}
iris_testing <- iris_recipe %>% 
  #Used to extract the right dataset
  bake(testing(iris_split))

#View results
glimpse(iris_testing)
```

To load the training data into an object, use `juice()`.
```{r}
iris_training <- juice(iris_recipe)

glimpse(iris_training)
```

## Model Training
Multiple packages can fit the same type of model and each provides a unique interface. So it is not easy to switch between packages when running the same model.

*`tidymodels` replaces the interface and provides a single set of functions and arguments to define a model then fits the model against the requested modeling package*

```{r}
iris_ranger <- rand_forest(trees = 100, mode = "classification") %>% 
  #Uses `ranger` package
  set_engine("ranger") %>% 
  fit(Species ~ ., data = iris_training)

iris_ranger
```

Using `tidymodels` you can run the same model against `randomForest`

```{r}
iris_rf <- rand_forest(trees = 100, mode = "classification") %>% 
  set_engine("randomForest") %>% 
  fit(Species ~ ., data = iris_training)

iris_rf
```

## Predictions
The `predict()` function ru against a `parsnip` model returns a *tibble*. By default the prediction variable is called `.pred_class`. _baked testing data is used below_.

```{r}
predict(iris_ranger, iris_testing)
```

You can add predictions to the _baked_ testing data using `bind_cols()`.

```{r}
iris_ranger %>% 
  predict(iris_testing) %>% 
  bind_cols(iris_testing) %>% 
  glimpse()
```

## Model Validation
`metrics()` function measures the performance of the model. It automatically chooses metrics appropriate for a given type of model. The function *expects a tibble* that contains the actual results (`truth`) and what the model predicted (`estimate`)

```{r}
iris_ranger %>% 
  predict(iris_testing) %>% 
  bind_cols(iris_testing) %>% 
  metrics(truth = Species, estimate = .pred_class)
```

You can measure the same metrics against the `randomForest` model by replacing the model variable at the top of the code.

```{r}
iris_rf %>% 
  predict(iris_testing) %>% 
  bind_cols(iris_testing) %>% 
  metrics(truth = Species, estimate = .pred_class)
```

### Per classifier metrics
To get the probability for each possible predicted value, set the `type` argument to `prob`. This returns a tibble with as many variables as there are possible predicted values. Name defaults to the original value name, prefixed with `.pred_`

```{r}
iris_ranger %>% 
  predict(iris_testing, type = "prob") %>% 
  glimpse()
```

Use `bind_cols()`to add predictions to the baked testing dataset. 

```{r}
iris_probs <- iris_ranger %>% 
  predict(iris_testing, type = "prob") %>% 
  bind_cols(iris_testing)

glimpse(iris_probs)
```

Now everything is in one tibble and you can calculate curve methods - here we use `gain_curve()`.

```{r}
iris_probs %>% 
  gain_curve(Species, .pred_setosa:.pred_virginica) %>% 
  glimpse()
```

Using `autoplot()` makes a visualization using the ggplot2 package.

```{r}
iris_probs %>% 
  gain_curve(Species, .pred_setosa:.pred_virginica) %>% 
  autoplot()
```

Now viewing with `roc_curve()`:

```{r}
iris_probs%>%
  roc_curve(Species, .pred_setosa:.pred_virginica) %>%
  autoplot()
```

When you combine the two prediction models, you can measure the combined single predicted value and probability of each possible value.

```{r}
predict(iris_ranger, iris_testing, type = "prob") %>% 
  bind_cols(predict(iris_ranger, iris_testing)) %>% 
  bind_cols(select(iris_testing, Species)) %>% 
  glimpse()
```

Piping the result into `metrics()`:

```{r}
predict(iris_ranger, iris_testing, type = "prob") %>%
  bind_cols(predict(iris_ranger, iris_testing)) %>%
  bind_cols(select(iris_testing, Species)) %>%
  metrics(Species, .pred_setosa:.pred_virginica, estimate = .pred_class)
```

