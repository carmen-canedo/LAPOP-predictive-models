---
title: "12 - Reading MDSR Chapter 8"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# Chapter 8
## Statistical learning and predictive analytics

Graphics work well when there are two or three variables involved. We will now be looking at models outside of a regression framework.

The idea that a general specification for a model could be turned to a specific data set automatically has led to the field of *machine learning*.

Two main branches in machine learning:
1. Supervised learning - modeling a specific response variable as a function of some explanatory variable
   + Data being studied already include measurements of outcome variables.

2. Unsupervised learning - approaches to finding patterns or groupings in data where there is not clear response variable
   + Outcome is unmeasured, task is often framed as a search for otherwise **unmeasured features** of the cases.
   
## 8.1 Supervised learning
The basic goal of supervised learning is to find a *function* that accurately describes how different measured explanatory variables can be combined to make a prediction about a response variable.

A function represents a relationship between inputs and an output.

`~` is used to define what the output variable (or variable on the left) is and what the input variables (or predictors on the right) are.

Expressions look like this:

`diabetic ~ age + sex + weight + height`

Here, the variable `diabetic` is marked as the output, simply because it is on the left side of `~`. The variables age, sex, weight, and height are to be the inputs to the function.

You can also see:

`diabetc ~ .`

The dot to the right means "use all the available variables (except the output)". The object above has class `formula`.

There are several different goals that might motivate constructing a function.
  + *Predict the output given an input.* It is February, what will the temperature be? Or on June 15th in Northampton, Massachusetts, U.S.A. (latitude 42.3 deg N), how many hours of daylight will there be?
  
  + *Determine which variables are useful inputs.* It is obvious from experience that temperature is a function of season. But in less familiar situations, e.g., predicting diabetes, the relevant inputs are uncertain or unknown.
  
  + *Generate hypotheses.* For a scientist trying to figure out the causes of diabetes, it can be useful to construct a predictive model, then look to see what variables turn out to be related to the risk of developing this disorder. 
    ++ You might find that diet, age, and blood pressure are risk factors. Socioeconomic status is not a direct cause of diabetes, but it might be that there is an association through factors related to the accessibility of health care. 
    ++ That is a **hypothesis**, and one that you probably would not have thought of before finding a function relating risk of diabetes to those inputs.
    
  + *Understand how a system works.* For example, a reasonable function relating hours of daylight to day-of-the-year and latitude reveals that the northern and southern hemisphere have reversed patterns: Long days in the southern hemisphere will be short days in the northern hemisphere.
  
Depending on your motivation, the kind of model and the input variables my differ.

In understanding how a system works, the variables you use should be related to the actual, causal mechanisms involved, e.g., the genetics of diabetes. For predicting an output, it hardly matters what the casual mechanisms are. Instead, all that's required is that the inputs are known at a time *before* the prediction is to be made. 

## 8.2 Classifiers
A logistic regression model takes a set of *explanatory variables* and converts them into a probability.

The analyst specifies the form of the relationship and what kind of variables are included.

*Classifers* serve as models for categorical response variables (see notes for mathematical explanation)

Classifiers are an important complement to regression models - while regression models have a **quantitative response variable** and can be visualized on a geometric surface, classification models have a **categorical response variable** and are often visualized as a discrete surface (i.e., a tree).

### 8.2.1 Decision trees
A decision tree assigns class labels to individual observations.

Each branch of the tree separates the records in the data set into increasingly "pure" (homogenous) subsets -- in the sense that they are *more likely to share the same class label.*

The number of possible decision tress grows exponentially with respect to the number of variables, p.

There isn't really an efficient algorithm to determine the optimal decision tree.

This book uses **recursive partitioning** decision trees using the package `rpart`.

The partitioning in a decision tree follow's Hunt's aglorithm, which is recursive.

A decision tree works by running this algorithm on the full training data set.

What does it mean to say that a set of records is "purer" than another set? Two popular methods for measuring purity of a set cadidate child nodes are the *Gini coefficient* and the *information gain*. Both are implemented in `rpart()`, which uses the Gini measurement by default.

8.2.2 Example: High-earners in the 1994 United States

A marketing analyst might be interested in finding factors that can be used to predict whether a potential customer is a high-earner. The 1994 United States Census provides information that can inform such a model, with records from 32,561 adults that include a binary variable indicating whether each person makes greater or less thatn $50,000. *This is our response variable*

```{r}
#Reading in data and saving to object
census <- read.csv(  "http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data",  header = FALSE) 

#Adding column names
names(census) <- c("age", "workclass", "fnlwgt", "education",  "education.num", "marital.status", "occupation", "relationship",  "race", "sex", "capital.gain", "capital.loss", "hours.per.week",  "native.country", "income") 

glimpse(census)
```

First, we will separate our data set into two pieces by separating the rows at random.

A sample with 80% of the rows will become the **training** data set, and the remaining 20% will be the **testing** data set.

```{r}
#Setting the seed
set.seed(364)

#Assigning row length to object n
n <- nrow(census)

#Creating testing data set
test_idx <- sample.int(n, size = round(0.2 * n))

#Creating training data set
train <- census[-test_idx, ]

#Number of rows in training data set
nrow(train)

#Reassigning test data set
test <- census[test_idx, ]
nrow(test)
```

Note that only about 24% of those in the sample make more than $50k.

Thus, the **accuracy** of the **null model** is about 76% since we can get that many right by just predicting that everyone makes less than $50k.

```{r}
tally(~income, data = train, format = "percent")
```

```{r}
library(rpart)
rpart(income ~ capital.gain, data = train)
```

Although nearly 80% of those who paid less than 5095.5 dollars in capital gains tax made less than $50k, about 95% of those who paid **more**. Thus, partitioning the recods according to this criterion helps to divide them into relatively purer subsets.

```{r}
#Setting point of partition
split <- 5095.5

#Adding new column
train <- train %>% 
  mutate(hi_cap_gains = capital.gain >= split)

ggplot(data = train, aes(x = capital.gain, y = income)) +
  geom_count(aes(color = hi_cap_gains),
             position = position_jitter(width = 0, height = 0.1), alpha = 0.5) +
  geom_vline(xintercept = split, color = "dodgerblue", lty = 2) +
  scale_x_log10(labels = scales::dollar)
```
Thus, this decision tree uses a single variable (`capital.gains`) to partition the data set into two parts: those who paid more than 5095.5 dollars in capital gains, and those who did not.

For the former-who make up 0.951 of all observations-we get 79.4% right by predicting that they made less than $50k.

For the latter, we get 95% right by predicting that they made more than $50k.

Thus, our overall accuracy jumps to 80.1%, easily besting the 75.7% in the null model.

How did the algorithm now to pick $5095 as the threshold value?

It tried all of the sensible values, and this was the one that lowered the Gini coefficient the most.

So far we've only used one variable, but we can build a decision tree for income in terms of all of the other variables in the dataset.

```{r}
form <- as.formula("income ~ age + workclass + education + marital.status + occupation + relationship + race + sex + capital.gain + capital.loss + hours.per.week")

mod_tree <- rpart(form, data = train)
mod_tree
```

